{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tekst data i Python: Håndtering af tekstdata og ’text mining’\n",
    "\n",
    "I dag ser vi på, hvordan tekster kan analyseres kvantitativt. Der introduceres diverse \"text mining\"-teknikker samt usuperviseret maskinlæring i form af latent dirichlet allocation til at inddele tekster i temaer.\n",
    "\n",
    "Der arbejdes med data fra Twitter og fra Reddit i løbet af sessionen.\n",
    "\n",
    "**Indhold**\n",
    "1. Introduktion: Tekst og maskinlæring\n",
    "2. Håndtering af tekst (strings) i Python\n",
    "3. Bearbejdning/\"pre-processing\" af tekst (tokenization)\n",
    "4. Introduktion til sprogmodeller\n",
    "5. Tokenization med sprogmodeller\n",
    "6. Simple text mining teknikker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hvorfor beskæftige sig med tekst kvantitativt?\n",
    "\n",
    "![climatenw](.././img/climatenw.png)\n",
    "\n",
    "Tekst har altid været en yderst relevant datakilde for samfundsvidenskaberne; om så det gælder artikler, interviewtransskriberinger, juridiske dokumenter, nyheder eller andet. \n",
    "\n",
    "Derudover produceres der uanede mængder af tekstdata fra sociale medier som Facebook, Twitter, Reddit osv. Internettet og sociale medier er i dag unægteligt forbundet til det sociale liv. \n",
    "\n",
    "**Udfordringen med tekstdata**\n",
    "\n",
    "Fra et analytisk synspunkt er der to primære udfordringer med tekst: volumen (der er rigtig meget af det) og formatet (det er ustruktureret). I samfundsvidenskaberne har man derfor længe opgivet kvantitativ analyse af tekst, da de kvantitative metoder, som oftest anvendes i samfundsvidenskaberne, ikke egner sig til denne type data. Som konsekvens deraf, har tekstdata automatisk været forbundet med kvalitativ analyse.\n",
    "\n",
    "Kvalitativ analyse kan dog ikke håndtere udfordringen om volumen: Et menneske kan ikke alene behandle så meget information. Behandling af store datamængder er netop det computerteknologi hjælper os med, og i dag findes der også mange teknikker til at analysere tekstdata kvantitativt. Dog kan det diskuteres, om disse (på nuværende tidspunkt) kan tjene som en erstatning for den kvalitative forskning, eller om teknikkerne kan bidrage til at kvalificere, validere eller informere kvalitativ forskning. \n",
    "\n",
    "**Muligheder med kvantitative/computationelle metoder**\n",
    "\n",
    "Selvom der i dag findes mange metoder og teknikker til at behandle tekst, så er brugen af disse til at bedrive samfundsvidenskabelig forskning stadig ikke særlig udbredt. Det betyder på den ene side, at der er mange uudforskede muligheder derude, men det betyder også, at der ikke er etableret faste traditioner for brug af disse metoder, og der er ej heller konsensus om, hvordan output af maskinlæringsmodeller brugt på tekst skal tolkes epistemologisk.\n",
    "\n",
    "Formålet med dagens lektion er at introducere til brug af kvantiative metoder på tekst, men der argumenteres ikke for, at disse kan erstatte den kvalitative forskning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tekst og maskinlæring\n",
    "\n",
    "Overordnet set hjælper maskinlæring på tekst med én ting: klassifikation. \n",
    "\n",
    "*Superviseret* maskinlæring kan hjælpe med at klassificere tekst efter kategorier, som er kendte af forskeren. Her listes nogen eksempler på brug af superviseret maskinlæring på tekst:\n",
    "- Sentiment analysis: Kategorisering af tekst efter udtryke følelser (fx positiv/negativ)\n",
    "- Named Entity Recognition (NER): Identificering af nøgleoplysninger i tekst (fx navne, virksomheder)\n",
    "- Generel klassificering: Hvad handler tekststykket om?\n",
    "- Brug af sprogmodeller: Sætningskonstruktion, tekstopbygning\n",
    "- Word embedding teknikker: Analyse af ords betydning gennem deres kontekst (computationelt)\n",
    "\n",
    "Fælles for superviseret maskinlæring på tekst er, at modeller skal gives information om, hvordan kategorier ser ud i teksten. Dette sker ofte gennem manuel kategorisering/annotering (kaldes også at træne en model).\n",
    "\n",
    "*Usuperviseret* maskinlæring kan hjælpe os med at klassificere tekst efter kategorier, som *ikke* er kendt af forskeren. Det inkluderer blandt andet:\n",
    "- Klyngeanalyser: Gruppering efter ensartethed af teksterne\n",
    "- Topic models: Udledning af underliggende emner i teksterne\n",
    "- Netværksanalyser: Ord i kontekst analyseret som netværk (visuelt)\n",
    "\n",
    "\n",
    "Fælles for usuperviseret maskinlæring på tekst er, at de de gives minimalt input ift. at kunne producere et output, der hjælper til at kategorisere eller inddele data. Dog er disse teknikker typisk meget sårbare over for måden, som man har forudbehandlet data (hvilke ord man har frasorteret, fx).\n",
    "\n",
    "## \"Natural language processing\" og \"text mining\"\n",
    "\n",
    "Man støder på to hovedtermer, når man arbejder kvantitativt med tekst: \"Natural language processing\" og \"text mining\". De to termer bruges lidt synonymt, men er bundet op på forskellige traditioner og ophav. \n",
    "\n",
    "**\"Natural language processing\" (NLP)** er først og fremmest en computervidenskabelig disciplin. Det er en disciplin, der beskæftiger sig med at få en computer til at forstå menneskeligt sprog (talt eller skrevet). Tale-til-tekst applikationer, stemmestyring, autocorrect er alle sammen baseret på natural language processing. \n",
    "\n",
    "Hvis I vil se et eksempel på førende NLP-teknologi i aktion, kan I tage et kig på [AI Dungeon](https://play.aidungeon.io/).\n",
    "\n",
    "![aidungeon](.././img/aidungeon.png)\n",
    "\n",
    "**\"Text mining\"** er primært et dataanalyse-term, der referer til metoder og teknikker, som udleder indhold, mønstre osv. i tekstdata. Text mining gør brug af NLP, da det er teknikkerne udviklet i NLP, der hjælper os til at få computeren til at forstå teksten, som vi undersøger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text mining workflow i Python: Et eksempel\n",
    "\n",
    "Herunder ses et eksempel på et text mining workflow i Python.\n",
    "\n",
    "Det indeholder følgende:\n",
    "- Import af relevante pakker\n",
    "- Indlæsning af data\n",
    "- Definere tokenizer funktion (med `spaCy`)\n",
    "- Tokenize tekstdata\n",
    "- Konverter data til tidy format\n",
    "- Ordoptælling (her hyppigste termer i tweets fordelt på politisk parti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import af pakker\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import spacy\n",
    "\n",
    "# Download ressourcer\n",
    "#!python -m spacy download da_core_news_sm # download sprogmodel\n",
    "\n",
    "# Sæt visualiseringsindstillinger\n",
    "%matplotlib inline\n",
    "sns.set(rc={'figure.figsize':(20,10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5500, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indlæsning af data\n",
    "tweetdata_url = \"https://raw.githubusercontent.com/CALDISS-AAU/course_ddf/master/datasets/poltweets_sample.csv\"\n",
    "tweets_df = pd.read_csv(tweetdata_url)\n",
    "tweets_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definer tokenizer\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"da_core_news_sm\") # Indlæser sprogmodel\n",
    "\n",
    "def tokenizer_spacy(text): \n",
    "    custom_stops = [\"god\", \"al\", \"stor\", \"ny\", \"tak\", \"dag\"] \n",
    "    default_stopwords = list(nlp.Defaults.stop_words) \n",
    "    stop_words = default_stopwords + custom_stops \n",
    "    pos_tags = ['PROPN', 'ADJ', 'NOUN'] \n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    tokens = []\n",
    "\n",
    "    for word in doc:\n",
    "        if word.lemma_.startswith(\"@\"): \n",
    "            continue \n",
    "        if word.lemma_.startswith(\"#\"):\n",
    "            continue \n",
    "        if (len(word.lemma_) < 3):\n",
    "            continue\n",
    "        if (word.pos_ in pos_tags) and (word.lemma_ not in stop_words): \n",
    "            tokens.append(word.lemma_)\n",
    "                \n",
    "    return(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anvend tokenizer på data (tager lang tid, så indlæs i forvejen tokenized data)\n",
    "tweets_df['tokens'] = tweets_df['full_text'].apply(tokenizer_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Indlæs tokenized data, hvis nødvendigt\n",
    "#import ast\n",
    "#tweets_df = pd.read_csv(\"https://raw.githubusercontent.com/CALDISS-AAU/course_ddf/master/datasets/poltweets_sample_tokens.csv\")\n",
    "#tweets_df['tokens'] = tweets_df['tokens'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Top 10 tokens for ALTERNATIVET----\n",
      "\n",
      "dkpol       170\n",
      "dksocial     46\n",
      "dkgreen      31\n",
      "Tak          23\n",
      "grøn         19\n",
      "regering     16\n",
      "udsætte      14\n",
      "arbejde      13\n",
      "social       13\n",
      "barn         13\n",
      "Name: tokens, dtype: int64\n",
      "\n",
      "\n",
      "----Top 10 tokens for DANSK FOLKEPARTI----\n",
      "\n",
      "dkpol       211\n",
      "Danmark      33\n",
      "regering     21\n",
      "dansk        20\n",
      "mangen       19\n",
      "dansker      17\n",
      "gang         15\n",
      "land         13\n",
      "dkmedier     13\n",
      "Tak          12\n",
      "Name: tokens, dtype: int64\n",
      "\n",
      "\n",
      "----Top 10 tokens for DET KONSERVATIVE FOLKEPARTI----\n",
      "\n",
      "dkpol         100\n",
      "Tak            31\n",
      "mangen         18\n",
      "dansk          15\n",
      "regering       14\n",
      "gang           13\n",
      "enig           13\n",
      "Danmark        12\n",
      "megen          11\n",
      "virksomhed     11\n",
      "Name: tokens, dtype: int64\n",
      "\n",
      "\n",
      "----Top 10 tokens for ENHEDSLISTEN----\n",
      "\n",
      "dkpol           200\n",
      "dkgreen          32\n",
      "regering         30\n",
      "Enhedslisten     20\n",
      "brug             20\n",
      "vigtig           18\n",
      "penge            17\n",
      "grøn             16\n",
      "barn             16\n",
      "gang             15\n",
      "Name: tokens, dtype: int64\n",
      "\n",
      "\n",
      "----Top 10 tokens for LIBERAL ALLIANCE----\n",
      "\n",
      "dkpol        171\n",
      "penge         25\n",
      "regering      19\n",
      "høj           17\n",
      "tid           17\n",
      "mangen        16\n",
      "problem       15\n",
      "skatte        14\n",
      "Danmark       14\n",
      "offentlig     13\n",
      "Name: tokens, dtype: int64\n",
      "\n",
      "\n",
      "----Top 10 tokens for NYE BORGERLIGE----\n",
      "\n",
      "dkpol         108\n",
      "Danmark        53\n",
      "Nye            52\n",
      "Borgerlige     37\n",
      "dansker        31\n",
      "dansk          30\n",
      "politiker      26\n",
      "dkmedier       25\n",
      "barn           21\n",
      "land           20\n",
      "Name: tokens, dtype: int64\n",
      "\n",
      "\n",
      "----Top 10 tokens for RADIKALE VENSTRE----\n",
      "\n",
      "dkpol      132\n",
      "Tak         26\n",
      "dansk       17\n",
      "megen       14\n",
      "mangen      13\n",
      "barn        13\n",
      "Danmark     13\n",
      "radikal     13\n",
      "gode        13\n",
      "tid         12\n",
      "Name: tokens, dtype: int64\n",
      "\n",
      "\n",
      "----Top 10 tokens for SOCIALDEMOKRATIET----\n",
      "\n",
      "dkpol       190\n",
      "regering     23\n",
      "mangen       21\n",
      "Tak          21\n",
      "Danmark      20\n",
      "gang         20\n",
      "barn         19\n",
      "stærk        12\n",
      "penge        11\n",
      "dktrp        11\n",
      "Name: tokens, dtype: int64\n",
      "\n",
      "\n",
      "----Top 10 tokens for SOCIALISTISK FOLKEPARTI----\n",
      "\n",
      "dkpol       172\n",
      "barn         34\n",
      "brug         20\n",
      "mangen       20\n",
      "forslag      20\n",
      "dkgreen      18\n",
      "tid          18\n",
      "vigtig       18\n",
      "regering     17\n",
      "grøn         17\n",
      "Name: tokens, dtype: int64\n",
      "\n",
      "\n",
      "----Top 10 tokens for UDEN FOR FOLKETINGSGRUPPERNE----\n",
      "\n",
      "dkpol       164\n",
      "Tak          30\n",
      "Danmark      30\n",
      "grøn         22\n",
      "dkmedier     22\n",
      "gang         19\n",
      "regering     18\n",
      "dansk        18\n",
      "dkgreen      18\n",
      "barn         18\n",
      "Name: tokens, dtype: int64\n",
      "\n",
      "\n",
      "----Top 10 tokens for VENSTRE----\n",
      "\n",
      "dkpol       209\n",
      "regering     39\n",
      "Danmark      25\n",
      "dansk        21\n",
      "Tak          21\n",
      "valg         17\n",
      "dansker      17\n",
      ":-)          14\n",
      "gang         13\n",
      "megen        13\n",
      "Name: tokens, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Data til tidy format\n",
    "tweets_df_tidy = tweets_df.explode('tokens')\n",
    "\n",
    "# Optælling af top 10 tokens for hvert parti\n",
    "for party in tweets_df_tidy['party'].unique():\n",
    "    print(f\"----Top 10 tokens for {party.upper()}----\\n\")\n",
    "    print(tweets_df_tidy.loc[tweets_df_tidy['party'] == party, 'tokens'].value_counts()[0:10])\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
