{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ØVELSE 1: Simpel teksthåndtering\n",
    "\n",
    "I øvelserne i dag skal i arbejde med et datasæt bestående af kommentarer fra reddit. Alle kommentarer er taget fra posts på r/denmark (reddit.com/r/denmark) fra 1/3-8/3 2021.\n",
    "\n",
    "1. Indlæs data som en pandas data frame\n",
    "    - Link til data: https://raw.githubusercontent.com/CALDISS-AAU/course_ddf/master/datasets/reddit_rdenmark-comments_01032021-08032021_long.csv\n",
    "2. Dan et subset bestående af alle kommentarer, der nævner \"menneskerettigheder\" (kommentarteksten er i kolonnen `comment_body`). Hvor mange kommentarer er der?\n",
    "\n",
    "**Bonus**\n",
    "- Kan du udregne gennemsnitsscore for de kommentarer, der nævner menneskerettigheder? (score fremgår af kolonnen `comment_score`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ØVELSE 2: Brug af sprogmodel\n",
    "\n",
    "1. Udvælg en enkelt kommentar fra reddit datasættet. Kommentarteksten findes i kolonnen \"comment_body\" (fx `comment = reddit_df.loc[200, 'comment_body']`)\n",
    "\n",
    "2. Analysér kommentaren med spaCy sprogmodellen (omdan kommentaren til et `doc` objekt). Husk at installér og indlæs sprogmodellen først:\n",
    "\n",
    "```\n",
    "import spacy\n",
    "\n",
    "!python -m spacy download da_core_news_sm\n",
    "nlp = spacy.load(\"da_core_news_sm\")\n",
    "```\n",
    "\n",
    "3. Er der named entities i kommentaren? (`doc.ents`) I så fald hvilke?\n",
    "\n",
    "**Bonus**\n",
    "\n",
    "- Lav en liste, der kun indeholder ord fra kommentaren med ordklassen \"NOUN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ØVELSE 3: Meningsfulde tokens med spaCy\n",
    "\n",
    "Prøv at undersøge find frem til de meningsfulde tokens af et reddit opslag. Opslagsteksten findes i kolonnen \"post_selftext\" (fx `post = reddit_df.loc[503, 'post_selftext']`)\n",
    "\n",
    "1. Skriv en tokenizer funktion, der bruger `spaCy`\n",
    "2. Tokenize opslaget med funktionen\n",
    "3. Lav en ordoptælling ved at konvertere jeres tokens til en pandas series og bruge `.value_counts()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ØVELSE 4: Tidy text data (reddit data)\n",
    "\n",
    "Du skal nu anvende din funktion fra før på alle *kommentarerne* i reddit datasættet (kolonnen `comment_body`)\n",
    "\n",
    "1. Brug `.apply()` til at anvende din tokenizer funktion på hele reddit datasættet til at lave en tokens kolonne (det kan være en god ide at teste funktionen med en enkelt kommentar først)\n",
    "2. Brug `.explode()` til at konvertere data til et tidy format\n",
    "3. Brug `.value_counts()` til at optælle tokens\n",
    "\n",
    "**Bonus**\n",
    "\n",
    "- Undersøg, hvor mange gange coronavirus er nævnt (tænkt gerne synonymer med!)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
